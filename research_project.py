import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import urllib3
import time

# [ì„¤ì •] SSL ë³´ì•ˆ ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì •ë¶€ ê³¼ì œ ëª¨ë‹ˆí„°ë§ (Custom)", page_icon="âš™ï¸", layout="wide")

# [ìë™ ìƒˆë¡œê³ ì¹¨] 1ì‹œê°„
refresh_sec = 3600 
st.markdown(
    f"""
    <meta http-equiv="refresh" content="{refresh_sec}">
    <script>
        setTimeout(function(){{
            window.location.reload(1);
        }}, {refresh_sec * 1000});
    </script>
    """,
    unsafe_allow_html=True
)

# --- 2. [í•µì‹¬] í‚¤ì›Œë“œ ê´€ë¦¬ ì‹œìŠ¤í…œ (Session State) ---
# í”„ë¡œê·¸ë¨ì´ ì²˜ìŒ ì‹¤í–‰ë  ë•Œ ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
if 'my_keywords' not in st.session_state:
    st.session_state.my_keywords = ["ìë™ì°¨", "ì—°êµ¬ê³¼ì œ", "ì—°êµ¬", "R&D", "ì¹œí™˜ê²½", "ì†Œì¬", "ë°°í„°ë¦¬", "ëª¨ë¹Œë¦¬í‹°"]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Connection": "keep-alive"
}

# --- 3. ë„êµ¬ í•¨ìˆ˜ë“¤ ---
def calculate_d_day(date_str):
    if not date_str or date_str == "-": return "-"
    try:
        clean = str(date_str).replace(".", "-").replace("/", "-").strip()
        end_date = datetime.strptime(clean, "%Y-%m-%d").date()
        today = datetime.now().date()
        diff = (end_date - today).days
        
        if diff < 0: return "ë§ˆê°ë¨"
        elif diff == 0: return "D-Day"
        else: return f"D-{diff}"
    except:
        return "-"

def is_target(title, keywords_list):
    """ì œëª©ì— ì‚¬ìš©ìê°€ ì„¤ì •í•œ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸"""
    if not title: return False
    for k in keywords_list:
        if k in title: return True
    return False

def get_soup(url):
    try:
        res = requests.get(url, headers=HEADERS, verify=False, timeout=10)
        res.encoding = res.apparent_encoding
        if res.status_code == 200:
            return BeautifulSoup(res.text, "html.parser")
    except: pass
    return None

# --- 4. í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ (í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¸ìë¡œ ë°›ìŒ) ---
def scrape_keit(keywords):
    results = []
    url = "https://www.keit.re.kr/board/list.do?boardId=BBS_0000004"
    try:
        soup = get_soup(url)
        if soup:
            rows = soup.select("table tbody tr")
            for row in rows:
                try:
                    title_tag = row.select_one("td.subject a") or row.select_one("a")
                    date_tag = row.select_one("td:nth-child(5)")
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        date_txt = date_tag.get_text(strip=True) if date_tag else "-"
                        if is_target(title, keywords):
                            results.append({"ì¶œì²˜": "KEIT", "ê³µê³ ëª…": title, "ë§ˆê°ì¼": date_txt, "ë§í¬": url})
                except: continue
    except: pass
    return results

def scrape_mss(keywords):
    results = []
    url = "https://www.smtech.go.kr/front/ifg/no/notice01_list.do"
    try:
        soup = get_soup(url)
        if soup:
            rows = soup.select("table.tbl_list tbody tr")
            for row in rows:
                try:
                    title_tag = row.select_one("td.l a")
                    date_tag = row.select_one("td:nth-child(4)")
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        date_txt = date_tag.get_text(strip=True) if date_tag else "-"
                        if is_target(title, keywords):
                            results.append({"ì¶œì²˜": "SMTECH", "ê³µê³ ëª…": title, "ë§ˆê°ì¼": date_txt, "ë§í¬": url})
                except: continue
    except: pass
    return results

def scrape_motie(keywords):
    results = []
    url = "https://www.motie.go.kr/kor/article/ATCL3f49a5a8c/list.do"
    try:
        soup = get_soup(url)
        if soup:
            rows = soup.select("table tbody tr")
            for row in rows:
                try:
                    title_tag = row.select_one("td.subject a")
                    date_tag = row.select_one("td.date")
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        date_txt = date_tag.get_text(strip=True) if date_tag else datetime.now().strftime("%Y-%m-%d")
                        if is_target(title, keywords):
                            results.append({"ì¶œì²˜": "MOTIE", "ê³µê³ ëª…": title, "ë§ˆê°ì¼": date_txt, "ë§í¬": url})
                except: continue
    except: pass
    return results

def scrape_iris(keywords):
    results = []
    url = "https://www.iris.go.kr/contents/retrieveBusAnnouncementList.do"
    try:
        soup = get_soup(url)
        if soup:
            rows = soup.select("table tbody tr")
            for row in rows:
                try:
                    title_tag = row.select_one("td.tit a") or row.select_one("a")
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        if is_target(title, keywords):
                            results.append({"ì¶œì²˜": "IRIS", "ê³µê³ ëª…": title, "ë§ˆê°ì¼": "-", "ë§í¬": url})
                except: continue
    except: pass
    return results

def scrape_katech(keywords):
    results = []
    url = "https://www.katech.re.kr/katech/notice/notice.do"
    try:
        soup = get_soup(url)
        if soup:
            rows = soup.select("tbody tr")
            for row in rows:
                try:
                    title_tag = row.select_one("td.subject a")
                    date_tag = row.select_one("td.date")
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        date_txt = date_tag.get_text(strip=True) if date_tag else "-"
                        if is_target(title, keywords):
                            results.append({"ì¶œì²˜": "KATECH", "ê³µê³ ëª…": title, "ë§ˆê°ì¼": date_txt, "ë§í¬": url})
                except: continue
    except: pass
    return results

# --- 5. ë°ì´í„° í†µí•© í•¨ìˆ˜ (í‚¤ì›Œë“œê°€ ë°”ë€Œë©´ ìºì‹œë¥¼ ê°±ì‹ í•´ì•¼ í•¨) ---
@st.cache_data(ttl=3600, show_spinner="ğŸ“¡ ì„¤ì •ëœ í‚¤ì›Œë“œë¡œ ìŠ¤ìº” ì¤‘...")
def scrape_all_real_data(current_keywords):
    """
    current_keywords ì¸ìë¥¼ ë°›ì•„ì„œ, í‚¤ì›Œë“œê°€ ë°”ë€” ë•Œë§ˆë‹¤ 
    ìƒˆë¡œ í¬ë¡¤ë§ì„ í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
    """
    all_tasks = []
    
    all_tasks.extend(scrape_keit(current_keywords))
    all_tasks.extend(scrape_mss(current_keywords))
    all_tasks.extend(scrape_motie(current_keywords))
    all_tasks.extend(scrape_iris(current_keywords))
    all_tasks.extend(scrape_katech(current_keywords))
    
    return all_tasks, datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# --- 6. ë©”ì¸ í™”ë©´ ---

with st.sidebar:
    st.header("âš™ï¸ ê´€ì œ ì„¼í„° ì„¤ì •")
    
    # [ìƒˆë¡œìš´ ê¸°ëŠ¥] í‚¤ì›Œë“œ ì¶”ê°€/ì‚­ì œ UI
    st.subheader("ğŸ¯ íƒ€ê²Ÿ í‚¤ì›Œë“œ ê´€ë¦¬")
    
    # 1. í‚¤ì›Œë“œ ì¶”ê°€ ì…ë ¥ì°½
    new_keyword = st.text_input("ì¶”ê°€í•  í‚¤ì›Œë“œ ì…ë ¥", placeholder="ì˜ˆ: ë°˜ë„ì²´")
    if st.button("í‚¤ì›Œë“œ ì¶”ê°€"):
        if new_keyword and new_keyword not in st.session_state.my_keywords:
            st.session_state.my_keywords.append(new_keyword)
            st.rerun() # í™”ë©´ ì¦‰ì‹œ ìƒˆë¡œê³ ì¹¨
        elif new_keyword in st.session_state.my_keywords:
            st.warning("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í‚¤ì›Œë“œì…ë‹ˆë‹¤.")

    # 2. í‚¤ì›Œë“œ í™•ì¸ ë° ì‚­ì œ (ë©€í‹°ì…€ë ‰íŠ¸ ë°•ìŠ¤ ì´ìš©)
    # ì‚¬ìš©ìê°€ ì—¬ê¸°ì„œ Xë¥¼ ëˆŒëŸ¬ ì‚­ì œí•˜ë©´ session_stateì— ì¦‰ì‹œ ë°˜ì˜
    selected_keywords = st.multiselect(
        "í˜„ì¬ ì ìš©ëœ í‚¤ì›Œë“œ (ì‚­ì œí•˜ë ¤ë©´ X í´ë¦­)",
        options=st.session_state.my_keywords,
        default=st.session_state.my_keywords
    )
    
    # ë§Œì•½ ë©€í‹°ì…€ë ‰íŠ¸ì—ì„œ ë‚´ìš©ì´ ë°”ë€Œì—ˆë‹¤ë©´(ì‚­ì œ ë“±), ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
    if set(selected_keywords) != set(st.session_state.my_keywords):
        st.session_state.my_keywords = selected_keywords
        st.rerun()

    st.markdown("---")
    
    st.subheader("ğŸ“¡ ìˆ˜ì§‘ ì±„ë„ ìƒíƒœ")
    st.success("âœ… ì‹œìŠ¤í…œ ê°€ë™ ì¤‘")
    
    if st.button("ğŸ”„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸"):
        st.cache_data.clear()
        st.rerun()

st.title("ğŸ­ ì •ë¶€ ê³¼ì œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (Custom)")
st.markdown("### ğŸ“¡ ë‚´ê°€ ì„¤ì •í•œ í‚¤ì›Œë“œë¡œ 5ëŒ€ ê¸°ê´€ì„ ì‹¤ì‹œê°„ ìŠ¤ìº”í•©ë‹ˆë‹¤.")
st.divider()

# í˜„ì¬ ì„¤ì •ëœ í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§ ì‹¤í–‰
current_keywords_list = st.session_state.my_keywords
data_list, update_time = scrape_all_real_data(current_keywords_list)
df = pd.DataFrame(data_list)

if not df.empty:
    df['D-Day'] = df['ë§ˆê°ì¼'].apply(calculate_d_day)
    
    # ìƒë‹¨ ì§€í‘œ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìˆ˜ì§‘ëœ ê³µê³ ", f"{len(df)} ê±´")
    with col2:
        urgent_count = 0
        for d in df['D-Day']:
            if d == "D-Day": urgent_count += 1
            elif str(d).startswith("D-"):
                try:
                    if int(d.split("-")[1]) <= 7: urgent_count += 1
                except: pass
        st.metric("ğŸš¨ ë§ˆê° ì„ë°•", f"{urgent_count} ê±´")
    with col3:
        st.metric("ê¸°ì¤€ ë‚ ì§œ", datetime.now().strftime("%Y-%m-%d"))

    st.subheader("ğŸ“‹ ì‹¤ì‹œê°„ ê³µê³  ë¦¬ìŠ¤íŠ¸")
    st.dataframe(
        df,
        column_config={
            "ë§í¬": st.column_config.LinkColumn("ë°”ë¡œê°€ê¸°", display_text="ğŸ”— ì´ë™"),
            "D-Day": st.column_config.TextColumn("ìƒíƒœ"),
            "ê³µê³ ëª…": st.column_config.TextColumn("ê³µê³  ì œëª©", width="large")
        },
        hide_index=True,
        use_container_width=True
    )

    st.divider()
    st.subheader("ğŸ“Œ ìƒì„¸ ì •ë³´ ì¹´ë“œ")
    for index, row in df.iterrows():
        icon = "ğŸ“„"
        d_val = str(row['D-Day'])
        if d_val == "D-Day": icon = "ğŸ”¥"
        elif d_val.startswith("D-"):
            try:
                if int(d_val.split("-")[1]) <= 7: icon = "ğŸ”¥"
            except: pass
            
        with st.expander(f"{icon} [{d_val}] {row['ê³µê³ ëª…']}"):
            st.write(f"**ê¸°ê´€:** {row['ì¶œì²˜']}")
            st.write(f"**ë§ˆê°:** {row['ë§ˆê°ì¼']}")
            st.markdown(f"**[ê²Œì‹œíŒ ë°”ë¡œê°€ê¸°]({row['ë§í¬']})**")

else:
    st.warning("ğŸ“¢ í˜„ì¬ ì„¤ì •ëœ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.info(f"ğŸ” í˜„ì¬ í‚¤ì›Œë“œ: {', '.join(current_keywords_list)}")
    st.write("ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•´ ë³´ì„¸ìš”.")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ìˆ˜ì§‘ëœ ê³µê³ ", "0 ê±´")
    col2.metric("ë§ˆê° ì„ë°•", "0 ê±´")
    col3.metric("ê¸°ì¤€ ë‚ ì§œ", datetime.now().strftime("%Y-%m-%d"))

st.markdown("---")
st.caption(f"ìµœì¢… ì—…ë°ì´íŠ¸: {update_time}")
